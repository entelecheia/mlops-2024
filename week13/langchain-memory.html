
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>LangChain 모듈 - 메모리 &#8212; 머신러닝시스템 2024</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css?v=4c969af8" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-examples.css?v=e236af4b" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster.custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster.bundle.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-shadow.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-punk.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-noir.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-light.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-borderless.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/micromodal.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/jquery.js?v=5d32c60e"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script src="../_static/tabs.js?v=3ee01567"></script>
    <script src="../_static/js/hoverxref.js"></script>
    <script src="../_static/js/tooltipster.bundle.min.js"></script>
    <script src="../_static/js/micromodal.min.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-BQJE5V9RK2"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-BQJE5V9RK2');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-BQJE5V9RK2');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"tex": {"macros": {"N": "\\mathbb{N}", "floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"]}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'week13/langchain-memory';</script>
    <link rel="icon" href="https://assets.entelecheia.ai/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="MLOps 프로젝트" href="../projects/index.html" />
    <link rel="prev" title="LangChain 모듈 - 체인 (Chains)" href="langchain-chain.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
  
    <p class="title logo__title">머신러닝시스템 2024</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Home
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Lecture Notes</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../week01/index.html">Week 1</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../week01/intro.html">MLOps 소개</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../week02/index.html">Week 2</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../week02/devops.html">DevOps</a></li>
<li class="toctree-l2"><a class="reference internal" href="../week02/gitops.html">GitOps</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../week03/index.html">Week 3</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../week03/dotfiles.html">Dotfiles</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../week04/index.html">Week 4</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../week04/containerization.html">컨테이너화</a></li>
<li class="toctree-l2"><a class="reference internal" href="../week04/docker.html">Docker</a></li>
<li class="toctree-l2"><a class="reference internal" href="../week04/containerd.html"><code class="docutils literal notranslate"><span class="pre">containerd</span></code></a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../week05/index.html">Week 5</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../week05/hyperfast-docker.html">하이퍼패스트 도커 템플릿</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../week06/index.html">Week 6</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../week06/kubernetes.html">쿠버네티스</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../week07/index.html">Week 7</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../week07/bionic/index.html">Bionic-GPT</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../week07/bionic/introduction.html">Bionic-GPT Enterprise</a></li>
<li class="toctree-l3"><a class="reference internal" href="../week07/bionic/bare-metal.html">Kubernetes on Bare Metal</a></li>
<li class="toctree-l3"><a class="reference internal" href="../week07/bionic/installation.html">Installing Bionic</a></li>
<li class="toctree-l3"><a class="reference internal" href="../week07/bionic/gpu-preparation.html">GPU Node Preparation (Nvidia)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../week07/bionic/sso.html">Single Sign On</a></li>
<li class="toctree-l3"><a class="reference internal" href="../week07/bionic/tgi.html">TGI Inference Engine</a></li>
<li class="toctree-l3"><a class="reference internal" href="../week07/bionic/roles.html">Role Based Access Control</a></li>
<li class="toctree-l3"><a class="reference internal" href="../week07/bionic/pgadmin.html">Integrate pgAdmin</a></li>
<li class="toctree-l3"><a class="reference internal" href="../week07/bionic/upgrade.html">Upgrading Bionic</a></li>
<li class="toctree-l3"><a class="reference internal" href="../week07/bionic/jupyter-notebook.html">Adding a Jupyter Notebook</a></li>
<li class="toctree-l3"><a class="reference internal" href="../week07/bionic/visualise-rag.html">Visualising RAG data</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../week09/index.html">Week 9</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../week09/sec.html">보안 관리</a></li>
<li class="toctree-l2"><a class="reference internal" href="../week09/auth-enc-sign.html">인증, 암호화 및 서명</a></li>
<li class="toctree-l2"><a class="reference internal" href="../week09/age-gpg-ssh.html">SSH, GPG, AGE 소개</a></li>
<li class="toctree-l2"><a class="reference internal" href="../week09/pass.html">Unix 패스워드 관리자</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../week10/index.html">Week 10</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../week10/autotrain.html">AutoTrain Advanced</a></li>
<li class="toctree-l2"><a class="reference internal" href="../week10/installation.html">설치</a></li>
<li class="toctree-l2"><a class="reference internal" href="../week10/starting.html">시작하기</a></li>
<li class="toctree-l2"><a class="reference internal" href="../week10/llm_finetuning.html">LLM 파인튜닝</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../week11/index.html">Week 11</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../week11/llama-factory.html">LLaMA Factory를 활용한 LLM 파인튜닝</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../week12/index.html">Week 12</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../week12/langchain.html">LangChain</a></li>
<li class="toctree-l2"><a class="reference internal" href="../week12/langchain-io.html">LangChain - Model I/O</a></li>
<li class="toctree-l2"><a class="reference internal" href="../week12/langserve.html">LangServe로 배포하기</a></li>
<li class="toctree-l2"><a class="reference internal" href="../week12/langsmith.html">LangSmith 소개</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="index.html">Week 13</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="lcel.html">LangChain 표현 언어 (LCEL)</a></li>
<li class="toctree-l2"><a class="reference internal" href="langchain-retrieval.html">LangChain 모듈 - 검색</a></li>
<li class="toctree-l2"><a class="reference internal" href="langchain-chain.html">LangChain 모듈 - 체인 (Chains)</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">LangChain 모듈 - 메모리</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Projects</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../projects/index.html">MLOps 프로젝트</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../projects/202121010/index.html">202121010</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../projects/202121010/MMHuman3D/index.html">MMhuman3D 프로젝트</a></li>
<li class="toctree-l3"><a class="reference internal" href="../projects/202121010/LectureSync/index.html">LectureSync 프로젝트 보고서</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../projects/202021012/index.html">202021012</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../projects/202021012/DUSt3R/index.html">DUSt3R</a></li>
<li class="toctree-l3"><a class="reference internal" href="../projects/202021012/finetuning/index.html">파인튜닝(Fine-tuning)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../projects/202021012/RAG_project/index.html">RAG 프로젝트 - 제주 역사 관광지 가이드 llm</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../projects/setup.html">프로젝트 환경설정</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">About</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../syllabus/index.html">수업계획서</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about/index.html">만든 사람들</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Links</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://halla.ai">인공지능학과</a></li>
<li class="toctree-l1"><a class="reference external" href="https://os2024.halla.ai">운영체제 2024</a></li>
<li class="toctree-l1"><a class="reference external" href="https://mlops2024.halla.ai">머신러닝시스템 2024</a></li>
<li class="toctree-l1"><a class="reference external" href="https://cobots2024.halla.ai">협동로봇활용 2024</a></li>
<li class="toctree-l1"><a class="reference external" href="https://aibasics.halla.ai">AI 세상 속으로</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/chu-aie/mlops-2024" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/chu-aie/mlops-2024/edit/main/src/mlops2024/book/week13/langchain-memory.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/chu-aie/mlops-2024/issues/new?title=Issue%20on%20page%20%2Fweek13/langchain-memory.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/week13/langchain-memory.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>LangChain 모듈 - 메모리</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">시스템에 메모리 구축하기</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">LangChain의 메모리 유형</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conversation-buffer-memory">대화 버퍼 메모리 (Conversation Buffer Memory)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conversation-buffer-window-memory">대화 버퍼 창 메모리 (Conversation Buffer Window Memory)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conversation-entity-memory">대화 엔티티 메모리 (Conversation Entity Memory)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conversation-knowledge-graph-memory">대화 지식 그래프 메모리 (Conversation Knowledge Graph Memory)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conversation-summary-memory">대화 요약 메모리 (Conversation Summary Memory)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conversation-summary-buffer-memory">대화 요약 버퍼 메모리 (Conversation Summary Buffer Memory)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conversation-token-buffer-memory">대화 토큰 버퍼 메모리 (Conversation Token Buffer Memory)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vectorstoreretrievermemory">VectorStoreRetrieverMemory</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">코드 예제</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">체인에서 사용</a></li>
</ul>
</li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="langchain">
<h1>LangChain 모듈 - 메모리<a class="headerlink" href="#langchain" title="Link to this heading">#</a></h1>
<p>LangChain에서 메모리는 대화형 인터페이스의 근본적인 측면으로, 시스템이 과거의 상호작용을 참조할 수 있게 합니다. 이는 정보를 저장하고 조회하는 과정을 통해 이루어지며, 주로 읽기와 쓰기의 두 가지 주요 작업이 포함됩니다. 메모리 시스템은 실행 중에 체인과 두 번 상호작용하며, 사용자 입력을 증강하고 입력 및 출력을 저장하여 향후 참조할 수 있게 합니다.</p>
<section id="id1">
<h2>시스템에 메모리 구축하기<a class="headerlink" href="#id1" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p><strong>채팅 메시지 저장:</strong> LangChain 메모리 모듈은 메모리 목록에서 데이터베이스에 이르기까지 다양한 방법을 통합하여 채팅 메시지를 저장합니다. 이를 통해 모든 채팅 상호작용이 기록되어 나중에 참조할 수 있습니다.</p></li>
<li><p><strong>채팅 메시지 조회:</strong> 메시지를 저장하는 것 외에도, LangChain은 이러한 메시지를 유용하게 보기 위해 데이터 구조 및 알고리즘을 사용합니다. 간단한 메모리 시스템은 최근 메시지를 반환할 수 있지만, 더 고급 시스템은 과거 상호작용을 요약하거나 현재 상호작용에서 언급된 엔티티에 집중할 수 있습니다.</p></li>
</ol>
<p>LangChain에서 메모리 사용을 보여주기 위해 <code class="docutils literal notranslate"><span class="pre">ConversationBufferMemory</span></code> 클래스를 예로 들어보겠습니다. 이는 채팅 메시지를 버퍼에 저장하는 간단한 메모리 형태입니다. 다음은 예제 코드입니다:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.memory</span> <span class="kn">import</span> <span class="n">ConversationBufferMemory</span>

<span class="n">memory</span> <span class="o">=</span> <span class="n">ConversationBufferMemory</span><span class="p">()</span>
<span class="n">memory</span><span class="o">.</span><span class="n">chat_memory</span><span class="o">.</span><span class="n">add_user_message</span><span class="p">(</span><span class="s2">&quot;Hello!&quot;</span><span class="p">)</span>
<span class="n">memory</span><span class="o">.</span><span class="n">chat_memory</span><span class="o">.</span><span class="n">add_ai_message</span><span class="p">(</span><span class="s2">&quot;How can I assist you?&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>메모리를 체인에 통합할 때, 메모리에서 반환된 변수를 이해하고 이를 체인에서 어떻게 사용하는지 이해하는 것이 중요합니다. 예를 들어, <code class="docutils literal notranslate"><span class="pre">load_memory_variables</span></code> 메서드는 메모리에서 읽어온 변수를 체인의 기대와 맞추는 데 도움이 됩니다.</p>
<p><strong>LangChain을 사용한 엔드투엔드 예제</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">ConversationBufferMemory</span></code>를 <code class="docutils literal notranslate"><span class="pre">LLMChain</span></code>에서 사용하는 예제를 살펴보겠습니다. 체인과 적절한 프롬프트 템플릿 및 메모리가 결합되어 일관되고 맥락을 이해하는 대화 경험을 제공합니다. 다음은 간단한 예제입니다:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">OpenAI</span>
<span class="kn">from</span> <span class="nn">langchain.prompts</span> <span class="kn">import</span> <span class="n">PromptTemplate</span>
<span class="kn">from</span> <span class="nn">langchain.chains</span> <span class="kn">import</span> <span class="n">LLMChain</span>
<span class="kn">from</span> <span class="nn">langchain.memory</span> <span class="kn">import</span> <span class="n">ConversationBufferMemory</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">template</span> <span class="o">=</span> <span class="s2">&quot;Your conversation template here...&quot;</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="n">PromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="n">template</span><span class="p">)</span>
<span class="n">memory</span> <span class="o">=</span> <span class="n">ConversationBufferMemory</span><span class="p">(</span><span class="n">memory_key</span><span class="o">=</span><span class="s2">&quot;chat_history&quot;</span><span class="p">)</span>
<span class="n">conversation</span> <span class="o">=</span> <span class="n">LLMChain</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span> <span class="n">memory</span><span class="o">=</span><span class="n">memory</span><span class="p">)</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">conversation</span><span class="p">({</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;What&#39;s the weather like?&quot;</span><span class="p">})</span>
</pre></div>
</div>
<p>이 예제는 LangChain의 메모리 시스템이 체인과 어떻게 통합되어 일관되고 맥락을 이해하는 대화 경험을 제공하는지 보여줍니다.</p>
</section>
<section id="id2">
<h2>LangChain의 메모리 유형<a class="headerlink" href="#id2" title="Link to this heading">#</a></h2>
<p>LangChain은 AI 모델과의 상호작용을 향상시키기 위해 다양한 메모리 유형을 제공합니다. 각 메모리 유형은 고유한 매개변수와 반환 유형을 가지고 있어, 다양한 시나리오에 적합합니다. LangChain에서 사용할 수 있는 몇 가지 메모리 유형과 코드 예제를 살펴보겠습니다.</p>
<section id="conversation-buffer-memory">
<h3>대화 버퍼 메모리 (Conversation Buffer Memory)<a class="headerlink" href="#conversation-buffer-memory" title="Link to this heading">#</a></h3>
<p>이 메모리 유형은 대화에서 메시지를 저장하고 추출할 수 있게 합니다. 대화의 역사를 문자열 또는 메시지 목록으로 추출할 수 있습니다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.memory</span> <span class="kn">import</span> <span class="n">ConversationBufferMemory</span>

<span class="n">memory</span> <span class="o">=</span> <span class="n">ConversationBufferMemory</span><span class="p">()</span>
<span class="n">memory</span><span class="o">.</span><span class="n">save_context</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;hi&quot;</span><span class="p">},</span> <span class="p">{</span><span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="s2">&quot;whats up&quot;</span><span class="p">})</span>
<span class="n">memory</span><span class="o">.</span><span class="n">load_memory_variables</span><span class="p">({})</span>

<span class="c1"># 역사(history)를 문자열로 추출</span>
<span class="p">{</span><span class="s1">&#39;history&#39;</span><span class="p">:</span> <span class="s1">&#39;Human: hi</span><span class="se">\n</span><span class="s1">AI: whats up&#39;</span><span class="p">}</span>

<span class="c1"># 역사(history)를 메시지 목록으로 추출</span>
<span class="p">{</span><span class="s1">&#39;history&#39;</span><span class="p">:</span> <span class="p">[</span>
  <span class="n">HumanMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="s1">&#39;hi&#39;</span><span class="p">,</span> <span class="n">additional_kwargs</span><span class="o">=</span><span class="p">{}),</span>
  <span class="n">AIMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="s1">&#39;whats up&#39;</span><span class="p">,</span> <span class="n">additional_kwargs</span><span class="o">=</span><span class="p">{})</span>
<span class="p">]}</span>
</pre></div>
</div>
<p>Conversation Buffer Memory는 채팅과 같은 상호작용을 위해 체인에 사용할 수도 있습니다.</p>
</section>
<section id="conversation-buffer-window-memory">
<h3>대화 버퍼 창 메모리 (Conversation Buffer Window Memory)<a class="headerlink" href="#conversation-buffer-window-memory" title="Link to this heading">#</a></h3>
<p>이 메모리 유형은 최근 상호작용 목록을 유지하며, 마지막 K개의 상호작용을 사용합니다. 이를 통해 버퍼가 너무 커지는 것을 방지합니다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.memory</span> <span class="kn">import</span> <span class="n">ConversationBufferWindowMemory</span>

<span class="n">memory</span> <span class="o">=</span> <span class="n">ConversationBufferWindowMemory</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">memory</span><span class="o">.</span><span class="n">save_context</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;hi&quot;</span><span class="p">},</span> <span class="p">{</span><span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="s2">&quot;whats up&quot;</span><span class="p">})</span>
<span class="n">memory</span><span class="o">.</span><span class="n">save_context</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;not much you&quot;</span><span class="p">},</span> <span class="p">{</span><span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="s2">&quot;not much&quot;</span><span class="p">})</span>
<span class="n">memory</span><span class="o">.</span><span class="n">load_memory_variables</span><span class="p">({})</span>

<span class="p">{</span><span class="s1">&#39;history&#39;</span><span class="p">:</span> <span class="s1">&#39;Human: not much you</span><span class="se">\n</span><span class="s1">AI: not much&#39;</span><span class="p">}</span>
</pre></div>
</div>
<p>대화 버퍼 메모리와 마찬가지로, 이 메모리 유형도 채팅과 같은 상호작용을 위해 체인에 사용할 수 있습니다.</p>
</section>
<section id="conversation-entity-memory">
<h3>대화 엔티티 메모리 (Conversation Entity Memory)<a class="headerlink" href="#conversation-entity-memory" title="Link to this heading">#</a></h3>
<p>이 메모리 유형은 대화에서 특정 엔티티에 대한 사실을 기억하고 LLM을 사용하여 정보를 추출합니다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.memory</span> <span class="kn">import</span> <span class="n">ConversationEntityMemory</span>
<span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">OpenAI</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">memory</span> <span class="o">=</span> <span class="n">ConversationEntityMemory</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">)</span>
<span class="n">_input</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;Deven &amp; Sam are working on a hackathon project&quot;</span><span class="p">}</span>
<span class="n">memory</span><span class="o">.</span><span class="n">load_memory_variables</span><span class="p">(</span><span class="n">_input</span><span class="p">)</span>
<span class="n">memory</span><span class="o">.</span><span class="n">save_context</span><span class="p">(</span>
    <span class="n">_input</span><span class="p">,</span>
    <span class="p">{</span><span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="s2">&quot; That sounds like a great project! What kind of project are they working on?&quot;</span><span class="p">}</span>
<span class="p">)</span>
<span class="n">memory</span><span class="o">.</span><span class="n">load_memory_variables</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s1">&#39;who is Sam&#39;</span><span class="p">})</span>

<span class="p">{</span><span class="s1">&#39;history&#39;</span><span class="p">:</span> <span class="s1">&#39;Human: Deven &amp; Sam are working on a hackathon project</span><span class="se">\n</span><span class="s1">AI:  That sounds like a great project! What kind of project are they working on?&#39;</span><span class="p">,</span>
 <span class="s1">&#39;entities&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Sam&#39;</span><span class="p">:</span> <span class="s1">&#39;Sam is working on a hackathon project with Deven.&#39;</span><span class="p">}}</span>
</pre></div>
</div>
</section>
<section id="conversation-knowledge-graph-memory">
<h3>대화 지식 그래프 메모리 (Conversation Knowledge Graph Memory)<a class="headerlink" href="#conversation-knowledge-graph-memory" title="Link to this heading">#</a></h3>
<p>이 메모리 유형은 지식 그래프를 사용하여 메모리를 재구성합니다. 메시지에서 현재 엔티티와 지식 삼중항을 추출할 수 있습니다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.memory</span> <span class="kn">import</span> <span class="n">ConversationKGMemory</span>
<span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">OpenAI</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">memory</span> <span class="o">=</span> <span class="n">ConversationKGMemory</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">)</span>
<span class="n">memory</span><span class="o">.</span><span class="n">save_context</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;say hi to sam&quot;</span><span class="p">},</span> <span class="p">{</span><span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="s2">&quot;who is sam&quot;</span><span class="p">})</span>
<span class="n">memory</span><span class="o">.</span><span class="n">save_context</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;sam is a friend&quot;</span><span class="p">},</span> <span class="p">{</span><span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="s2">&quot;okay&quot;</span><span class="p">})</span>
<span class="n">memory</span><span class="o">.</span><span class="n">load_memory_variables</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;who is sam&quot;</span><span class="p">})</span>

<span class="p">{</span><span class="s1">&#39;history&#39;</span><span class="p">:</span> <span class="s1">&#39;On Sam: Sam is friend.&#39;</span><span class="p">}</span>
</pre></div>
</div>
<p>이 메모리 유형은 대화 기반 지식 검색을 위해 체인에 사용할 수도 있습니다.</p>
</section>
<section id="conversation-summary-memory">
<h3>대화 요약 메모리 (Conversation Summary Memory)<a class="headerlink" href="#conversation-summary-memory" title="Link to this heading">#</a></h3>
<p>이 메모리 유형은 시간에 따라 대화의 요약을 생성하며, 긴 대화에서 정보를 요약하는 데 유용합니다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.memory</span> <span class="kn">import</span> <span class="n">ConversationSummaryMemory</span>
<span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">OpenAI</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">memory</span> <span class="o">=</span> <span class="n">ConversationSummaryMemory</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">)</span>
<span class="n">memory</span><span class="o">.</span><span class="n">save_context</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;hi&quot;</span><span class="p">},</span> <span class="p">{</span><span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="s2">&quot;whats up&quot;</span><span class="p">})</span>
<span class="n">memory</span><span class="o">.</span><span class="n">load_memory_variables</span><span class="p">({})</span>

<span class="p">{</span><span class="s1">&#39;history&#39;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">The human greets the AI, to which the AI responds.&#39;</span><span class="p">}</span>
</pre></div>
</div>
</section>
<section id="conversation-summary-buffer-memory">
<h3>대화 요약 버퍼 메모리 (Conversation Summary Buffer Memory)<a class="headerlink" href="#conversation-summary-buffer-memory" title="Link to this heading">#</a></h3>
<p>이 메모리 유형은 대화 요약과 버퍼를 결합하여 최근 상호작용과 요약 간의 균형을 유지합니다. 토큰 길이를 사용하여 상호작용을 플러시할 때를 결정합니다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.memory</span> <span class="kn">import</span> <span class="n">ConversationSummaryBufferMemory</span>
<span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">OpenAI</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">()</span>
<span class="n">memory</span> <span class="o">=</span> <span class="n">ConversationSummaryBufferMemory</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span> <span class="n">max_token_limit</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">memory</span><span class="o">.</span><span class="n">save_context</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;hi&quot;</span><span class="p">},</span> <span class="p">{</span><span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="s2">&quot;whats up&quot;</span><span class="p">})</span>
<span class="n">memory</span><span class="o">.</span><span class="n">save_context</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;not much you&quot;</span><span class="p">},</span> <span class="p">{</span><span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="s2">&quot;not much&quot;</span><span class="p">})</span>
<span class="n">memory</span><span class="o">.</span><span class="n">load_memory_variables</span><span class="p">({})</span>

<span class="p">{</span><span class="s1">&#39;history&#39;</span><span class="p">:</span> <span class="s1">&#39;System: </span><span class="se">\n</span><span class="s1">The human says &quot;hi&quot;, and the AI responds with &quot;whats up&quot;.</span><span class="se">\n</span><span class="s1">Human: not much you</span><span class="se">\n</span><span class="s1">AI: not much&#39;</span><span class="p">}</span>
</pre></div>
</div>
<p>이러한 메모리 유형을 사용하여 LangChain에서 AI 모델과의 상호작용을 향상시킬 수 있습니다. 각 메모리 유형은 특정 목적에 맞게 설계되었으며, 요구 사항에 따라 선택할 수 있습니다.</p>
</section>
<section id="conversation-token-buffer-memory">
<h3>대화 토큰 버퍼 메모리 (Conversation Token Buffer Memory)<a class="headerlink" href="#conversation-token-buffer-memory" title="Link to this heading">#</a></h3>
<p>Conversation Token Buffer Memory는 최근 상호작용을 메모리에 저장하는 또 다른 메모리 유형입니다. 이전의 메모리 유형들이 상호작용의 수에 초점을 맞춘 것과 달리, 이 메모리는 토큰 길이를 사용하여 상호작용을 플러시할 때를 결정합니다.</p>
<p>LLM과 함께 사용하는 예제:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.memory</span> <span class="kn">import</span> <span class="n">ConversationTokenBufferMemory</span>
<span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">OpenAI</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">()</span>

<span class="n">memory</span> <span class="o">=</span> <span class="n">ConversationTokenBufferMemory</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span> <span class="n">max_token_limit</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">memory</span><span class="o">.</span><span class="n">save_context</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;hi&quot;</span><span class="p">},</span> <span class="p">{</span><span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="s2">&quot;whats up&quot;</span><span class="p">})</span>
<span class="n">memory</span><span class="o">.</span><span class="n">save_context</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;not much you&quot;</span><span class="p">},</span> <span class="p">{</span><span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="s2">&quot;not much&quot;</span><span class="p">})</span>

<span class="n">memory</span><span class="o">.</span><span class="n">load_memory_variables</span><span class="p">({})</span>

<span class="p">{</span><span class="s1">&#39;history&#39;</span><span class="p">:</span> <span class="s1">&#39;Human: not much you</span><span class="se">\n</span><span class="s1">AI: not much&#39;</span><span class="p">}</span>
</pre></div>
</div>
<p>이 예제에서는 메모리가 상호작용의 수가 아닌 토큰 길이에 따라 상호작용을 제한하도록 설정됩니다.</p>
<p>메시지 목록으로 역사를 가져오는 방법:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">memory</span> <span class="o">=</span> <span class="n">ConversationTokenBufferMemory</span><span class="p">(</span>
    <span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span> <span class="n">max_token_limit</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">return_messages</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<span class="n">memory</span><span class="o">.</span><span class="n">save_context</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;hi&quot;</span><span class="p">},</span> <span class="p">{</span><span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="s2">&quot;whats up&quot;</span><span class="p">})</span>
<span class="n">memory</span><span class="o">.</span><span class="n">save_context</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;not much you&quot;</span><span class="p">},</span> <span class="p">{</span><span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="s2">&quot;not much&quot;</span><span class="p">})</span>
</pre></div>
</div>
<p>체인에서 사용하는 예제:</p>
<p>ConversationTokenBufferMemory를 체인에서 사용하여 AI 모델과의 상호작용을 관리할 수 있습니다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.chains</span> <span class="kn">import</span> <span class="n">ConversationChain</span>

<span class="n">conversation_with_summary</span> <span class="o">=</span> <span class="n">ConversationChain</span><span class="p">(</span>
    <span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span>
    <span class="c1"># 테스트 목적으로 max_token_limit을 매우 낮게 설정</span>
    <span class="n">memory</span><span class="o">=</span><span class="n">ConversationTokenBufferMemory</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">OpenAI</span><span class="p">(),</span> <span class="n">max_token_limit</span><span class="o">=</span><span class="mi">60</span><span class="p">),</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">conversation_with_summary</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="s2">&quot;Hi, what&#39;s up?&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>이 예제에서 ConversationTokenBufferMemory는 ConversationChain에서 사용되어 대화를 관리하고 토큰 길이에 따라 상호작용을 제한합니다.</p>
</section>
<section id="vectorstoreretrievermemory">
<h3>VectorStoreRetrieverMemory<a class="headerlink" href="#vectorstoreretrievermemory" title="Link to this heading">#</a></h3>
<p><strong>VectorStoreRetrieverMemory</strong>는 메모리를 벡터 스토어에 저장하고, 호출될 때마다 가장 “중요한” 상위 K개의 문서를 쿼리합니다. 이 메모리 유형은 상호작용의 순서를 명시적으로 추적하지 않고 벡터 검색을 사용하여 관련 메모리를 가져옵니다.</p>
<section id="id3">
<h4>코드 예제<a class="headerlink" href="#id3" title="Link to this heading">#</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">from</span> <span class="nn">langchain.embeddings.openai</span> <span class="kn">import</span> <span class="n">OpenAIEmbeddings</span>
<span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">OpenAI</span>
<span class="kn">from</span> <span class="nn">langchain.memory</span> <span class="kn">import</span> <span class="n">VectorStoreRetrieverMemory</span>
<span class="kn">from</span> <span class="nn">langchain.chains</span> <span class="kn">import</span> <span class="n">ConversationChain</span>
<span class="kn">from</span> <span class="nn">langchain.prompts</span> <span class="kn">import</span> <span class="n">PromptTemplate</span>

<span class="c1"># 벡터 스토어 초기화</span>
<span class="kn">import</span> <span class="nn">faiss</span>
<span class="kn">from</span> <span class="nn">langchain.docstore</span> <span class="kn">import</span> <span class="n">InMemoryDocstore</span>
<span class="kn">from</span> <span class="nn">langchain.vectorstores</span> <span class="kn">import</span> <span class="n">FAISS</span>

<span class="n">embedding_size</span> <span class="o">=</span> <span class="mi">1536</span>  <span class="c1"># OpenAIEmbeddings의 차원 수</span>
<span class="n">index</span> <span class="o">=</span> <span class="n">faiss</span><span class="o">.</span><span class="n">IndexFlatL2</span><span class="p">(</span><span class="n">embedding_size</span><span class="p">)</span>
<span class="n">embedding_fn</span> <span class="o">=</span> <span class="n">OpenAIEmbeddings</span><span class="p">()</span><span class="o">.</span><span class="n">embed_query</span>
<span class="n">vectorstore</span> <span class="o">=</span> <span class="n">FAISS</span><span class="p">(</span><span class="n">embedding_fn</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">InMemoryDocstore</span><span class="p">({}),</span> <span class="p">{})</span>

<span class="c1"># VectorStoreRetrieverMemory 생성</span>
<span class="n">retriever</span> <span class="o">=</span> <span class="n">vectorstore</span><span class="o">.</span><span class="n">as_retriever</span><span class="p">(</span><span class="n">search_kwargs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="n">memory</span> <span class="o">=</span> <span class="n">VectorStoreRetrieverMemory</span><span class="p">(</span><span class="n">retriever</span><span class="o">=</span><span class="n">retriever</span><span class="p">)</span>

<span class="c1"># 컨텍스트와 관련 정보를 메모리에 저장</span>
<span class="n">memory</span><span class="o">.</span><span class="n">save_context</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;My favorite food is pizza&quot;</span><span class="p">},</span> <span class="p">{</span><span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="s2">&quot;that&#39;s good to know&quot;</span><span class="p">})</span>
<span class="n">memory</span><span class="o">.</span><span class="n">save_context</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;My favorite sport is soccer&quot;</span><span class="p">},</span> <span class="p">{</span><span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="s2">&quot;...&quot;</span><span class="p">})</span>
<span class="n">memory</span><span class="o">.</span><span class="n">save_context</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;I don&#39;t like the Celtics&quot;</span><span class="p">},</span> <span class="p">{</span><span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="s2">&quot;ok&quot;</span><span class="p">})</span>

<span class="c1"># 쿼리를 기반으로 메모리에서 관련 정보 검색</span>
<span class="nb">print</span><span class="p">(</span><span class="n">memory</span><span class="o">.</span><span class="n">load_memory_variables</span><span class="p">({</span><span class="s2">&quot;prompt&quot;</span><span class="p">:</span> <span class="s2">&quot;what sport should i watch?&quot;</span><span class="p">})[</span><span class="s2">&quot;history&quot;</span><span class="p">])</span>
</pre></div>
</div>
<p>이 예제에서 <strong>VectorStoreRetrieverMemory</strong>는 대화에서 중요한 정보를 벡터 스토어에 저장하고, 쿼리할 때 관련 메모리를 검색합니다. 이를 통해 순서를 추적하지 않고도 중요한 정보를 효율적으로 찾을 수 있습니다.</p>
</section>
<section id="id4">
<h4>체인에서 사용<a class="headerlink" href="#id4" title="Link to this heading">#</a></h4>
<p><strong>VectorStoreRetrieverMemory</strong>를 체인에서 사용하여 대화 기반 지식 검색을 강화할 수 있습니다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.chains</span> <span class="kn">import</span> <span class="n">ConversationChain</span>

<span class="n">conversation_with_summary</span> <span class="o">=</span> <span class="n">ConversationChain</span><span class="p">(</span>
    <span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span>
    <span class="c1"># 테스트 목적으로 max_token_limit을 매우 낮게 설정</span>
    <span class="n">memory</span><span class="o">=</span><span class="n">VectorStoreRetrieverMemory</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">OpenAI</span><span class="p">(),</span> <span class="n">max_token_limit</span><span class="o">=</span><span class="mi">60</span><span class="p">),</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">conversation_with_summary</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="s2">&quot;Hi, what&#39;s up?&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>이 예제에서 <strong>VectorStoreRetrieverMemory</strong>는 <strong>ConversationChain</strong>에서 사용되어 대화를 관리하고 토큰 길이에 따라 상호작용을 제한합니다.</p>
</section>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "chu-aie/mlops-2024",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./week13"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="langchain-chain.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">LangChain 모듈 - 체인 (Chains)</p>
      </div>
    </a>
    <a class="right-next"
       href="../projects/index.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">MLOps 프로젝트</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">시스템에 메모리 구축하기</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">LangChain의 메모리 유형</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conversation-buffer-memory">대화 버퍼 메모리 (Conversation Buffer Memory)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conversation-buffer-window-memory">대화 버퍼 창 메모리 (Conversation Buffer Window Memory)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conversation-entity-memory">대화 엔티티 메모리 (Conversation Entity Memory)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conversation-knowledge-graph-memory">대화 지식 그래프 메모리 (Conversation Knowledge Graph Memory)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conversation-summary-memory">대화 요약 메모리 (Conversation Summary Memory)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conversation-summary-buffer-memory">대화 요약 버퍼 메모리 (Conversation Summary Buffer Memory)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conversation-token-buffer-memory">대화 토큰 버퍼 메모리 (Conversation Token Buffer Memory)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vectorstoreretrievermemory">VectorStoreRetrieverMemory</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">코드 예제</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">체인에서 사용</a></li>
</ul>
</li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By <a href='https://entelecheia.me/'>Young Joon Lee</a>
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <script
  data-embed-id="ed04ae65-928c-4ab5-912d-ce49f76450b7"
  data-base-api-url="https://chat.entelecheia.app/api/embed"
  data-brand-image-url="https://assets.entelecheia.ai/favicon.png"
  data-chat-icon="magic"
  data-sponsor-text="MLOps 2024"
  data-sponsor-link="https://chat.entelecheia.app/workspace/mlops2024"
  src="https://chat.entelecheia.app/embed/anythingllm-chat-widget.min.js">
</script>

</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>