
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>LangChain 표현 언어 (LCEL) &#8212; 머신러닝시스템 2024</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css?v=4c969af8" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-examples.css?v=e236af4b" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster.custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster.bundle.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-shadow.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-punk.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-noir.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-light.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-borderless.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/micromodal.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/jquery.js?v=5d32c60e"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script src="../_static/tabs.js?v=3ee01567"></script>
    <script src="../_static/js/hoverxref.js"></script>
    <script src="../_static/js/tooltipster.bundle.min.js"></script>
    <script src="../_static/js/micromodal.min.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-BQJE5V9RK2"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-BQJE5V9RK2');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-BQJE5V9RK2');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"tex": {"macros": {"N": "\\mathbb{N}", "floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"]}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'week13/lcel';</script>
    <link rel="icon" href="https://assets.entelecheia.ai/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="LangChain 모듈 - 검색" href="langchain-retrieval.html" />
    <link rel="prev" title="Week 13" href="index.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
  
    <p class="title logo__title">머신러닝시스템 2024</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Home
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Lecture Notes</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../week01/index.html">Week 1</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../week01/intro.html">MLOps 소개</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../week02/index.html">Week 2</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../week02/devops.html">DevOps</a></li>
<li class="toctree-l2"><a class="reference internal" href="../week02/gitops.html">GitOps</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../week03/index.html">Week 3</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../week03/dotfiles.html">Dotfiles</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../week04/index.html">Week 4</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../week04/containerization.html">컨테이너화</a></li>
<li class="toctree-l2"><a class="reference internal" href="../week04/docker.html">Docker</a></li>
<li class="toctree-l2"><a class="reference internal" href="../week04/containerd.html"><code class="docutils literal notranslate"><span class="pre">containerd</span></code></a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../week05/index.html">Week 5</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../week05/hyperfast-docker.html">하이퍼패스트 도커 템플릿</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../week06/index.html">Week 6</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../week06/kubernetes.html">쿠버네티스</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../week07/index.html">Week 7</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../week07/bionic/index.html">Bionic-GPT</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../week07/bionic/introduction.html">Bionic-GPT Enterprise</a></li>
<li class="toctree-l3"><a class="reference internal" href="../week07/bionic/bare-metal.html">Kubernetes on Bare Metal</a></li>
<li class="toctree-l3"><a class="reference internal" href="../week07/bionic/installation.html">Installing Bionic</a></li>
<li class="toctree-l3"><a class="reference internal" href="../week07/bionic/gpu-preparation.html">GPU Node Preparation (Nvidia)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../week07/bionic/sso.html">Single Sign On</a></li>
<li class="toctree-l3"><a class="reference internal" href="../week07/bionic/tgi.html">TGI Inference Engine</a></li>
<li class="toctree-l3"><a class="reference internal" href="../week07/bionic/roles.html">Role Based Access Control</a></li>
<li class="toctree-l3"><a class="reference internal" href="../week07/bionic/pgadmin.html">Integrate pgAdmin</a></li>
<li class="toctree-l3"><a class="reference internal" href="../week07/bionic/upgrade.html">Upgrading Bionic</a></li>
<li class="toctree-l3"><a class="reference internal" href="../week07/bionic/jupyter-notebook.html">Adding a Jupyter Notebook</a></li>
<li class="toctree-l3"><a class="reference internal" href="../week07/bionic/visualise-rag.html">Visualising RAG data</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../week09/index.html">Week 9</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../week09/sec.html">보안 관리</a></li>
<li class="toctree-l2"><a class="reference internal" href="../week09/auth-enc-sign.html">인증, 암호화 및 서명</a></li>
<li class="toctree-l2"><a class="reference internal" href="../week09/age-gpg-ssh.html">SSH, GPG, AGE 소개</a></li>
<li class="toctree-l2"><a class="reference internal" href="../week09/pass.html">Unix 패스워드 관리자</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../week10/index.html">Week 10</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../week10/autotrain.html">AutoTrain Advanced</a></li>
<li class="toctree-l2"><a class="reference internal" href="../week10/installation.html">설치</a></li>
<li class="toctree-l2"><a class="reference internal" href="../week10/starting.html">시작하기</a></li>
<li class="toctree-l2"><a class="reference internal" href="../week10/llm_finetuning.html">LLM 파인튜닝</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../week11/index.html">Week 11</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../week11/llama-factory.html">LLaMA Factory를 활용한 LLM 파인튜닝</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../week12/index.html">Week 12</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../week12/langchain.html">LangChain</a></li>
<li class="toctree-l2"><a class="reference internal" href="../week12/langchain-io.html">LangChain - Model I/O</a></li>
<li class="toctree-l2"><a class="reference internal" href="../week12/langserve.html">LangServe로 배포하기</a></li>
<li class="toctree-l2"><a class="reference internal" href="../week12/langsmith.html">LangSmith 소개</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="index.html">Week 13</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">LangChain 표현 언어 (LCEL)</a></li>
<li class="toctree-l2"><a class="reference internal" href="langchain-retrieval.html">LangChain 모듈 - 검색</a></li>
<li class="toctree-l2"><a class="reference internal" href="langchain-chain.html">LangChain 모듈 - 체인 (Chains)</a></li>
<li class="toctree-l2"><a class="reference internal" href="langchain-memory.html">LangChain 모듈 - 메모리</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Projects</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../projects/index.html">MLOps 프로젝트</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../projects/202121010/index.html">202121010</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../projects/202121010/MMHuman3D/index.html">MMhuman3D 프로젝트</a></li>
<li class="toctree-l3"><a class="reference internal" href="../projects/202121010/LectureSync/index.html">LectureSync 프로젝트 보고서</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../projects/202021012/index.html">202021012</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../projects/202021012/DUSt3R/index.html">DUSt3R</a></li>
<li class="toctree-l3"><a class="reference internal" href="../projects/202021012/finetuning/index.html">파인튜닝(Fine-tuning)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../projects/202021012/RAG_project/index.html">RAG 프로젝트 - 제주 역사 관광지 가이드 llm</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../projects/setup.html">프로젝트 환경설정</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">About</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../syllabus/index.html">수업계획서</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about/index.html">만든 사람들</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Links</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://halla.ai">인공지능학과</a></li>
<li class="toctree-l1"><a class="reference external" href="https://os2024.halla.ai">운영체제 2024</a></li>
<li class="toctree-l1"><a class="reference external" href="https://mlops2024.halla.ai">머신러닝시스템 2024</a></li>
<li class="toctree-l1"><a class="reference external" href="https://cobots2024.halla.ai">협동로봇활용 2024</a></li>
<li class="toctree-l1"><a class="reference external" href="https://aibasics.halla.ai">AI 세상 속으로</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/chu-aie/mlops-2024" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/chu-aie/mlops-2024/edit/main/src/mlops2024/book/week13/lcel.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/chu-aie/mlops-2024/issues/new?title=Issue%20on%20page%20%2Fweek13/lcel.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/week13/lcel.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>LangChain 표현 언어 (LCEL)</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#llm">프롬프트 + LLM</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">프롬프트 + LLM + 출력 파서</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rag">RAG (검색 증강 생성)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">대화형 검색 체인</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">메모리 사용 및 소스 문서 반환</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">다중 체인</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">분기 및 병합</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lcel-python">LCEL을 사용하여 Python 코드 작성</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">체인에 메모리 추가</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#runnables">Runnables와 외부 도구 사용</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">LLM 애플리케이션에 중재 추가</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">의미론적 유사성에 의한 라우팅</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">에이전트 및 Runnables 사용</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sql">SQL 데이터베이스 쿼리</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="langchain-lcel">
<h1>LangChain 표현 언어 (LCEL)<a class="headerlink" href="#langchain-lcel" title="Link to this heading">#</a></h1>
<p>자연어 처리와 기계 학습 세계에서 복잡한 연산 체인을 구성하는 것은 어려운 작업일 수 있습니다. 다행히도 LangChain 표현 언어(LCEL)가 이를 해결해 주며, 정교한 언어 처리 파이프라인을 구축하고 배포하는 선언적이고 효율적인 방법을 제공합니다. LCEL은 체인 구성 프로세스를 단순화하도록 설계되어 프로토타이핑에서 프로덕션으로 쉽게 전환할 수 있습니다. 이 블로그에서는 LCEL이 무엇이고 왜 사용하는지 살펴보고, 그 기능을 보여주는 실제 코드 예제와 함께 설명하겠습니다.</p>
<p>LCEL 또는 LangChain 표현 언어는 언어 처리 체인을 구성하기 위한 강력한 도구입니다. 프로토타이핑에서 프로덕션으로 원활하게 전환하도록 설계되었으며, 광범위한 코드 변경이 필요하지 않습니다. 간단한 “프롬프트 + LLM” 체인을 구축하든 수백 개의 단계가 있는 복잡한 파이프라인을 구축하든 LCEL이 적용될 수 있습니다.</p>
<p>LCEL을 언어 처리 프로젝트에 사용해야 하는 이유는 다음과 같습니다:</p>
<ol class="arabic simple">
<li><p>빠른 토큰 스트리밍: LCEL은 언어 모델에서 출력 파서로 실시간으로 토큰을 전달하여 응답성과 효율성을 향상시킵니다.</p></li>
<li><p>다양한 API: LCEL은 프로토타이핑 및 프로덕션 사용을 위한 동기 및 비동기 API를 지원하여 여러 요청을 효율적으로 처리합니다.</p></li>
<li><p>자동 병렬화: LCEL은 가능한 경우 병렬 실행을 최적화하여 동기 및 비동기 인터페이스 모두에서 대기 시간을 줄입니다.</p></li>
<li><p>신뢰할 수 있는 구성: 규모에 맞게 재시도 및 대체를 구성하여 체인 신뢰성을 높이고 개발 중 스트리밍을 지원합니다.</p></li>
<li><p>중간 결과 스트리밍: 처리 중 중간 결과에 액세스하여 사용자 업데이트 또는 디버깅 목적으로 사용할 수 있습니다.</p></li>
<li><p>스키마 생성: LCEL은 입력 및 출력 유효성 검사를 위해 Pydantic 및 JSONSchema 스키마를 생성합니다.</p></li>
<li><p>포괄적인 추적: LangSmith는 복잡한 체인의 모든 단계를 자동으로 추적하여 관찰 가능성과 디버깅을 제공합니다.</p></li>
<li><p>쉬운 배포: LCEL로 생성된 체인을 LangServe를 사용하여 쉽게 배포할 수 있습니다.</p></li>
</ol>
<p>이제 LCEL의 강력함을 보여주는 실제 코드 예제를 살펴보겠습니다. LCEL이 빛나는 일반적인 작업과 시나리오를 탐구해 보겠습니다.</p>
<section id="llm">
<h2>프롬프트 + LLM<a class="headerlink" href="#llm" title="Link to this heading">#</a></h2>
<p>가장 기본적인 구성은 프롬프트와 언어 모델을 결합하여 사용자 입력을 받아 프롬프트에 추가하고 모델에 전달한 다음 원시 모델 출력을 반환하는 체인을 만드는 것입니다. 다음은 그 예시입니다:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.prompts</span> <span class="kn">import</span> <span class="n">ChatPromptTemplate</span>
<span class="kn">from</span> <span class="nn">langchain.chat_models</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="s2">&quot;tell me a joke about </span><span class="si">{foo}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">()</span>
<span class="n">chain</span> <span class="o">=</span> <span class="n">prompt</span> <span class="o">|</span> <span class="n">model</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;foo&quot;</span><span class="p">:</span> <span class="s2">&quot;bears&quot;</span><span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
<p>이 예제에서 체인은 곰에 대한 농담을 생성합니다.</p>
<p>체인에 중지 시퀀스를 첨부하여 텍스트 처리 방식을 제어할 수 있습니다. 예를 들면 다음과 같습니다:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">chain</span> <span class="o">=</span> <span class="n">prompt</span> <span class="o">|</span> <span class="n">model</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">stop</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">])</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;foo&quot;</span><span class="p">:</span> <span class="s2">&quot;bears&quot;</span><span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
<p>이 구성은 줄 바꿈 문자를 만나면 텍스트 생성을 중지합니다.</p>
<p>LCEL은 체인에 함수 호출 정보를 첨부하는 것을 지원합니다. 다음은 그 예시입니다:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">functions</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
        <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;joke&quot;</span><span class="p">,</span>
        <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;A joke&quot;</span><span class="p">,</span>
        <span class="s2">&quot;parameters&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;object&quot;</span><span class="p">,</span>
            <span class="s2">&quot;properties&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;setup&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;The setup for the joke&quot;</span><span class="p">},</span>
                <span class="s2">&quot;punchline&quot;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;The punchline for the joke&quot;</span><span class="p">,</span>
                <span class="p">},</span>
            <span class="p">},</span>
            <span class="s2">&quot;required&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;setup&quot;</span><span class="p">,</span> <span class="s2">&quot;punchline&quot;</span><span class="p">],</span>
        <span class="p">},</span>
    <span class="p">}</span>
<span class="p">]</span>
<span class="n">chain</span> <span class="o">=</span> <span class="n">prompt</span> <span class="o">|</span> <span class="n">model</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">function_call</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;joke&quot;</span><span class="p">},</span> <span class="n">functions</span><span class="o">=</span><span class="n">functions</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;foo&quot;</span><span class="p">:</span> <span class="s2">&quot;bears&quot;</span><span class="p">},</span> <span class="n">config</span><span class="o">=</span><span class="p">{})</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
<p>이 예제는 농담을 생성하기 위해 함수 호출 정보를 첨부합니다.</p>
</section>
<section id="id1">
<h2>프롬프트 + LLM + 출력 파서<a class="headerlink" href="#id1" title="Link to this heading">#</a></h2>
<p>원시 모델 출력을 보다 작업하기 쉬운 형식으로 변환하기 위해 출력 파서를 추가할 수 있습니다. 이렇게 할 수 있는 방법은 다음과 같습니다:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.schema.output_parser</span> <span class="kn">import</span> <span class="n">StrOutputParser</span>

<span class="n">chain</span> <span class="o">=</span> <span class="n">prompt</span> <span class="o">|</span> <span class="n">model</span> <span class="o">|</span> <span class="n">StrOutputParser</span><span class="p">()</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;foo&quot;</span><span class="p">:</span> <span class="s2">&quot;bears&quot;</span><span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
<p>이제 출력이 문자열 형식이므로 다운스트림 작업에 더 편리합니다.</p>
<p>반환할 함수를 지정할 때 LCEL을 사용하여 직접 구문 분석할 수 있습니다. 예를 들면 다음과 같습니다:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.output_parsers.openai_functions</span> <span class="kn">import</span> <span class="n">JsonOutputFunctionsParser</span>

<span class="n">chain</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">prompt</span>
    <span class="o">|</span> <span class="n">model</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">function_call</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;joke&quot;</span><span class="p">},</span> <span class="n">functions</span><span class="o">=</span><span class="n">functions</span><span class="p">)</span>
    <span class="o">|</span> <span class="n">JsonOutputFunctionsParser</span><span class="p">()</span>
<span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;foo&quot;</span><span class="p">:</span> <span class="s2">&quot;bears&quot;</span><span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
<p>이 예제는 “joke” 함수의 출력을 직접 구문 분석합니다.</p>
<p>이것들은 LCEL이 복잡한 언어 처리 작업을 단순화하는 방법의 몇 가지 예일 뿐입니다. 챗봇을 구축하든, 콘텐츠를 생성하든, 복잡한 텍스트 변환을 수행하든 LCEL은 워크플로우를 간소화하고 코드를 더 유지 관리하기 쉽게 만들 수 있습니다.</p>
</section>
<section id="rag">
<h2>RAG (검색 증강 생성)<a class="headerlink" href="#rag" title="Link to this heading">#</a></h2>
<p>LCEL은 검색과 언어 생성 단계를 결합하는 검색 증강 생성 체인을 생성하는 데 사용할 수 있습니다. 다음은 그 예시입니다:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">operator</span> <span class="kn">import</span> <span class="n">itemgetter</span>

<span class="kn">from</span> <span class="nn">langchain.prompts</span> <span class="kn">import</span> <span class="n">ChatPromptTemplate</span>
<span class="kn">from</span> <span class="nn">langchain.chat_models</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="kn">from</span> <span class="nn">langchain.embeddings</span> <span class="kn">import</span> <span class="n">OpenAIEmbeddings</span>
<span class="kn">from</span> <span class="nn">langchain.schema.output_parser</span> <span class="kn">import</span> <span class="n">StrOutputParser</span>
<span class="kn">from</span> <span class="nn">langchain.schema.runnable</span> <span class="kn">import</span> <span class="n">RunnablePassthrough</span><span class="p">,</span> <span class="n">RunnableLambda</span>
<span class="kn">from</span> <span class="nn">langchain.vectorstores</span> <span class="kn">import</span> <span class="n">FAISS</span>

<span class="c1"># Create a vector store and retriever</span>
<span class="n">vectorstore</span> <span class="o">=</span> <span class="n">FAISS</span><span class="o">.</span><span class="n">from_texts</span><span class="p">(</span>
    <span class="p">[</span><span class="s2">&quot;harrison worked at kensho&quot;</span><span class="p">],</span> <span class="n">embedding</span><span class="o">=</span><span class="n">OpenAIEmbeddings</span><span class="p">()</span>
<span class="p">)</span>
<span class="n">retriever</span> <span class="o">=</span> <span class="n">vectorstore</span><span class="o">.</span><span class="n">as_retriever</span><span class="p">()</span>

<span class="c1"># Define templates for prompts</span>
<span class="n">template</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;Answer the question based only on the following context:</span>
<span class="si">{context}</span>

<span class="s2">Question: </span><span class="si">{question}</span>
<span class="s2">&quot;&quot;&quot;</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="n">template</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">()</span>

<span class="c1"># Create a retrieval-augmented generation chain</span>
<span class="n">chain</span> <span class="o">=</span> <span class="p">(</span>
    <span class="p">{</span><span class="s2">&quot;context&quot;</span><span class="p">:</span> <span class="n">retriever</span><span class="p">,</span> <span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="n">RunnablePassthrough</span><span class="p">()}</span>
    <span class="o">|</span> <span class="n">prompt</span>
    <span class="o">|</span> <span class="n">model</span>
    <span class="o">|</span> <span class="n">StrOutputParser</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;where did harrison work?&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
<p>이 예제에서 체인은 컨텍스트에서 관련 정보를 검색하고 질문에 대한 응답을 생성합니다.</p>
</section>
<section id="id2">
<h2>대화형 검색 체인<a class="headerlink" href="#id2" title="Link to this heading">#</a></h2>
<p>대화 기록을 체인에 쉽게 추가할 수 있습니다. 다음은 대화형 검색 체인의 예시입니다:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.schema.runnable</span> <span class="kn">import</span> <span class="n">RunnableMap</span>
<span class="kn">from</span> <span class="nn">langchain.schema</span> <span class="kn">import</span> <span class="n">format_document</span>

<span class="kn">from</span> <span class="nn">langchain.prompts.prompt</span> <span class="kn">import</span> <span class="n">PromptTemplate</span>

<span class="c1"># Define templates for prompts</span>
<span class="n">_template</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.</span>

<span class="s2">Chat History:</span>
<span class="si">{chat_history}</span>
<span class="s2">Follow Up Input: </span><span class="si">{question}</span>
<span class="s2">Standalone question:&quot;&quot;&quot;</span>
<span class="n">CONDENSE_QUESTION_PROMPT</span> <span class="o">=</span> <span class="n">PromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="n">_template</span><span class="p">)</span>

<span class="n">template</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;Answer the question based only on the following context:</span>
<span class="si">{context}</span>

<span class="s2">Question: </span><span class="si">{question}</span>
<span class="s2">&quot;&quot;&quot;</span>
<span class="n">ANSWER_PROMPT</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="n">template</span><span class="p">)</span>

<span class="c1"># Define input map and context</span>
<span class="n">_inputs</span> <span class="o">=</span> <span class="n">RunnableMap</span><span class="p">(</span>
    <span class="n">standalone_question</span><span class="o">=</span><span class="n">RunnablePassthrough</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span>
        <span class="n">chat_history</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">_format_chat_history</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s2">&quot;chat_history&quot;</span><span class="p">])</span>
    <span class="p">)</span>
    <span class="o">|</span> <span class="n">CONDENSE_QUESTION_PROMPT</span>
    <span class="o">|</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="o">|</span> <span class="n">StrOutputParser</span><span class="p">(),</span>
<span class="p">)</span>
<span class="n">_context</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;context&quot;</span><span class="p">:</span> <span class="n">itemgetter</span><span class="p">(</span><span class="s2">&quot;standalone_question&quot;</span><span class="p">)</span> <span class="o">|</span> <span class="n">retriever</span> <span class="o">|</span> <span class="n">_combine_documents</span><span class="p">,</span>
    <span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;standalone_question&quot;</span><span class="p">],</span>
<span class="p">}</span>
<span class="n">conversational_qa_chain</span> <span class="o">=</span> <span class="n">_inputs</span> <span class="o">|</span> <span class="n">_context</span> <span class="o">|</span> <span class="n">ANSWER_PROMPT</span> <span class="o">|</span> <span class="n">ChatOpenAI</span><span class="p">()</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">conversational_qa_chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;where did harrison work?&quot;</span><span class="p">,</span>
        <span class="s2">&quot;chat_history&quot;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="p">}</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
<p>이 예제에서 체인은 대화 컨텍스트 내에서 후속 질문을 처리합니다.</p>
</section>
<section id="id3">
<h2>메모리 사용 및 소스 문서 반환<a class="headerlink" href="#id3" title="Link to this heading">#</a></h2>
<p>LCEL은 메모리 사용과 소스 문서 반환도 지원합니다. 다음은 체인에서 메모리를 사용하는 방법입니다:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">operator</span> <span class="kn">import</span> <span class="n">itemgetter</span>
<span class="kn">from</span> <span class="nn">langchain.memory</span> <span class="kn">import</span> <span class="n">ConversationBufferMemory</span>

<span class="c1"># Create a memory instance</span>
<span class="n">memory</span> <span class="o">=</span> <span class="n">ConversationBufferMemory</span><span class="p">(</span>
    <span class="n">return_messages</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">output_key</span><span class="o">=</span><span class="s2">&quot;answer&quot;</span><span class="p">,</span> <span class="n">input_key</span><span class="o">=</span><span class="s2">&quot;question&quot;</span>
<span class="p">)</span>

<span class="c1"># Define steps for the chain</span>
<span class="n">loaded_memory</span> <span class="o">=</span> <span class="n">RunnablePassthrough</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span>
    <span class="n">chat_history</span><span class="o">=</span><span class="n">RunnableLambda</span><span class="p">(</span><span class="n">memory</span><span class="o">.</span><span class="n">load_memory_variables</span><span class="p">)</span> <span class="o">|</span> <span class="n">itemgetter</span><span class="p">(</span><span class="s2">&quot;history&quot;</span><span class="p">),</span>
<span class="p">)</span>

<span class="n">standalone_question</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;standalone_question&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;question&quot;</span><span class="p">],</span>
        <span class="s2">&quot;chat_history&quot;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">_format_chat_history</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s2">&quot;chat_history&quot;</span><span class="p">]),</span>
    <span class="p">}</span>
    <span class="o">|</span> <span class="n">CONDENSE_QUESTION_PROMPT</span>
    <span class="o">|</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="o">|</span> <span class="n">StrOutputParser</span><span class="p">(),</span>
<span class="p">}</span>

<span class="n">retrieved_documents</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;docs&quot;</span><span class="p">:</span> <span class="n">itemgetter</span><span class="p">(</span><span class="s2">&quot;standalone_question&quot;</span><span class="p">)</span> <span class="o">|</span> <span class="n">retriever</span><span class="p">,</span>
    <span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;standalone_question&quot;</span><span class="p">],</span>
<span class="p">}</span>

<span class="n">final_inputs</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;context&quot;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">_combine_documents</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s2">&quot;docs&quot;</span><span class="p">]),</span>
    <span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="n">itemgetter</span><span class="p">(</span><span class="s2">&quot;question&quot;</span><span class="p">),</span>
<span class="p">}</span>

<span class="n">answer</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;answer&quot;</span><span class="p">:</span> <span class="n">final_inputs</span> <span class="o">|</span> <span class="n">ANSWER_PROMPT</span> <span class="o">|</span> <span class="n">ChatOpenAI</span><span class="p">(),</span>
    <span class="s2">&quot;docs&quot;</span><span class="p">:</span> <span class="n">itemgetter</span><span class="p">(</span><span class="s2">&quot;docs&quot;</span><span class="p">),</span>
<span class="p">}</span>

<span class="c1"># Create the final chain by combining the steps</span>
<span class="n">final_chain</span> <span class="o">=</span> <span class="n">loaded_memory</span> <span class="o">|</span> <span class="n">standalone_question</span> <span class="o">|</span> <span class="n">retrieved_documents</span> <span class="o">|</span> <span class="n">answer</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;where did harrison work?&quot;</span><span class="p">}</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">final_chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
<p>이 예제에서 메모리는 대화 기록과 소스 문서를 저장하고 검색하는 데 사용됩니다.</p>
</section>
<section id="id4">
<h2>다중 체인<a class="headerlink" href="#id4" title="Link to this heading">#</a></h2>
<p>Runnables를 사용하여 여러 체인을 연결할 수 있습니다. 다음은 분기 및 병합의 예시입니다:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">operator</span> <span class="kn">import</span> <span class="n">itemgetter</span>

<span class="kn">from</span> <span class="nn">langchain.chat_models</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="kn">from</span> <span class="nn">langchain.prompts</span> <span class="kn">import</span> <span class="n">ChatPromptTemplate</span>
<span class="kn">from</span> <span class="nn">langchain.schema</span> <span class="kn">import</span> <span class="n">StrOutputParser</span>

<span class="n">prompt1</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="s2">&quot;what is the city </span><span class="si">{person}</span><span class="s2"> is from?&quot;</span><span class="p">)</span>
<span class="n">prompt2</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span>
    <span class="s2">&quot;what country is the city </span><span class="si">{city}</span><span class="s2"> in? respond in </span><span class="si">{language}</span><span class="s2">&quot;</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">()</span>

<span class="n">chain1</span> <span class="o">=</span> <span class="n">prompt1</span> <span class="o">|</span> <span class="n">model</span> <span class="o">|</span> <span class="n">StrOutputParser</span><span class="p">()</span>

<span class="n">chain2</span> <span class="o">=</span> <span class="p">(</span>
    <span class="p">{</span><span class="s2">&quot;city&quot;</span><span class="p">:</span> <span class="n">chain1</span><span class="p">,</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="n">itemgetter</span><span class="p">(</span><span class="s2">&quot;language&quot;</span><span class="p">)}</span>
    <span class="o">|</span> <span class="n">prompt2</span>
    <span class="o">|</span> <span class="n">model</span>
    <span class="o">|</span> <span class="n">StrOutputParser</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">chain2</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;person&quot;</span><span class="p">:</span> <span class="s2">&quot;obama&quot;</span><span class="p">,</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;spanish&quot;</span><span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
<p>이 예제에서는 두 개의 체인이 결합되어 도시에 대한 정보와 지정된 언어로 해당 국가에 대한 정보를 생성합니다.</p>
</section>
<section id="id5">
<h2>분기 및 병합<a class="headerlink" href="#id5" title="Link to this heading">#</a></h2>
<p>LCEL을 사용하면 RunnableMaps를 사용하여 체인을 분할하고 병합할 수 있습니다. 다음은 분기 및 병합의 예시입니다:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">operator</span> <span class="kn">import</span> <span class="n">itemgetter</span>

<span class="kn">from</span> <span class="nn">langchain.chat_models</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="kn">from</span> <span class="nn">langchain.prompts</span> <span class="kn">import</span> <span class="n">ChatPromptTemplate</span>
<span class="kn">from</span> <span class="nn">langchain.schema</span> <span class="kn">import</span> <span class="n">StrOutputParser</span>

<span class="n">planner</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="s2">&quot;Generate an argument about: </span><span class="si">{input}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="o">|</span> <span class="n">ChatOpenAI</span><span class="p">()</span>
    <span class="o">|</span> <span class="n">StrOutputParser</span><span class="p">()</span>
    <span class="o">|</span> <span class="p">{</span><span class="s2">&quot;base_response&quot;</span><span class="p">:</span> <span class="n">RunnablePassthrough</span><span class="p">()}</span>
<span class="p">)</span>

<span class="n">arguments_for</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span>
        <span class="s2">&quot;List the pros or positive aspects of </span><span class="si">{base_response}</span><span class="s2">&quot;</span>
    <span class="p">)</span>
    <span class="o">|</span> <span class="n">ChatOpenAI</span><span class="p">()</span>
    <span class="o">|</span> <span class="n">StrOutputParser</span><span class="p">()</span>
<span class="p">)</span>
<span class="n">arguments_against</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span>
        <span class="s2">&quot;List the cons or negative aspects of </span><span class="si">{base_response}</span><span class="s2">&quot;</span>
    <span class="p">)</span>
    <span class="o">|</span> <span class="n">ChatOpenAI</span><span class="p">()</span>
    <span class="o">|</span> <span class="n">StrOutputParser</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">final_responder</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_messages</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="p">(</span><span class="s2">&quot;ai&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="si">{original_response}</span><span class="s2">&quot;</span><span class="p">),</span>
            <span class="p">(</span><span class="s2">&quot;human&quot;</span><span class="p">,</span> <span class="s2">&quot;Pros:</span><span class="se">\n</span><span class="si">{results_1}</span><span class="se">\n\n</span><span class="s2">Cons:</span><span class="se">\n</span><span class="si">{results_2}</span><span class="s2">&quot;</span><span class="p">),</span>
            <span class="p">(</span><span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;Generate a final response given the critique&quot;</span><span class="p">),</span>
        <span class="p">]</span>
    <span class="p">)</span>
    <span class="o">|</span> <span class="n">ChatOpenAI</span><span class="p">()</span>
    <span class="o">|</span> <span class="n">StrOutputParser</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">chain</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">planner</span>
    <span class="o">|</span> <span class="p">{</span>
        <span class="s2">&quot;results_1&quot;</span><span class="p">:</span> <span class="n">arguments_for</span><span class="p">,</span>
        <span class="s2">&quot;results_2&quot;</span><span class="p">:</span> <span class="n">arguments_against</span><span class="p">,</span>
        <span class="s2">&quot;original_response&quot;</span><span class="p">:</span> <span class="n">itemgetter</span><span class="p">(</span><span class="s2">&quot;base_response&quot;</span><span class="p">),</span>
    <span class="p">}</span>
    <span class="o">|</span> <span class="n">final_responder</span>
<span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;scrum&quot;</span><span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
<p>이 예제에서 분기 및 병합 체인은 인수를 생성하고 최종 응답을 생성하기 전에 장단점을 평가하는 데 사용됩니다.</p>
<section id="lcel-python">
<h3>LCEL을 사용하여 Python 코드 작성<a class="headerlink" href="#lcel-python" title="Link to this heading">#</a></h3>
<p>LangChain 표현 언어(LCEL)의 강력한 응용 프로그램 중 하나는 사용자 문제를 해결하기 위해 Python 코드를 작성하는 것입니다. 다음은 LCEL을 사용하여 Python 코드를 작성하는 방법의 예시입니다:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.chat_models</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="kn">from</span> <span class="nn">langchain.prompts</span> <span class="kn">import</span> <span class="n">ChatPromptTemplate</span>
<span class="kn">from</span> <span class="nn">langchain.schema.output_parser</span> <span class="kn">import</span> <span class="n">StrOutputParser</span>
<span class="kn">from</span> <span class="nn">langchain_experimental.utilities</span> <span class="kn">import</span> <span class="n">PythonREPL</span>

<span class="n">template</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;Write some python code to solve the user&#39;s problem.</span>

<span class="s2">Return only python code in Markdown format, e.g.:</span>

<span class="s2">```python</span>
<span class="s2">....</span>
<span class="s2">```&quot;&quot;&quot;</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_messages</span><span class="p">([(</span><span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="n">template</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;human&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="si">{input}</span><span class="s2">&quot;</span><span class="p">)])</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">_sanitize_output</span><span class="p">(</span><span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">after</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;```python&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">after</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;```&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">chain</span> <span class="o">=</span> <span class="n">prompt</span> <span class="o">|</span> <span class="n">model</span> <span class="o">|</span> <span class="n">StrOutputParser</span><span class="p">()</span> <span class="o">|</span> <span class="n">_sanitize_output</span> <span class="o">|</span> <span class="n">PythonREPL</span><span class="p">()</span><span class="o">.</span><span class="n">run</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;what&#39;s 2 plus 2&quot;</span><span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
<p>이 예제에서 사용자는 입력을 제공하고 LCEL은 문제를 해결하기 위해 Python 코드를 생성합니다. 그런 다음 Python REPL을 사용하여 코드를 실행하고 Markdown 형식으로 결과 Python 코드를 반환합니다.</p>
<p>Python REPL을 사용하면 임의의 코드를 실행할 수 있으므로 주의해서 사용하시기 바랍니다.</p>
</section>
<section id="id6">
<h3>체인에 메모리 추가<a class="headerlink" href="#id6" title="Link to this heading">#</a></h3>
<p>메모리는 많은 대화형 AI 애플리케이션에서 필수적입니다. 다음은 임의의 체인에 메모리를 추가하는 방법입니다:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">operator</span> <span class="kn">import</span> <span class="n">itemgetter</span>
<span class="kn">from</span> <span class="nn">langchain.chat_models</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="kn">from</span> <span class="nn">langchain.memory</span> <span class="kn">import</span> <span class="n">ConversationBufferMemory</span>
<span class="kn">from</span> <span class="nn">langchain.schema.runnable</span> <span class="kn">import</span> <span class="n">RunnablePassthrough</span><span class="p">,</span> <span class="n">RunnableLambda</span>
<span class="kn">from</span> <span class="nn">langchain.prompts</span> <span class="kn">import</span> <span class="n">ChatPromptTemplate</span><span class="p">,</span> <span class="n">MessagesPlaceholder</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">()</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_messages</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">(</span><span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;You are a helpful chatbot&quot;</span><span class="p">),</span>
        <span class="n">MessagesPlaceholder</span><span class="p">(</span><span class="n">variable_name</span><span class="o">=</span><span class="s2">&quot;history&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">&quot;human&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="si">{input}</span><span class="s2">&quot;</span><span class="p">),</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">memory</span> <span class="o">=</span> <span class="n">ConversationBufferMemory</span><span class="p">(</span><span class="n">return_messages</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Initialize memory</span>
<span class="n">memory</span><span class="o">.</span><span class="n">load_memory_variables</span><span class="p">({})</span>

<span class="n">chain</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">RunnablePassthrough</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span>
        <span class="n">history</span><span class="o">=</span><span class="n">RunnableLambda</span><span class="p">(</span><span class="n">memory</span><span class="o">.</span><span class="n">load_memory_variables</span><span class="p">)</span> <span class="o">|</span> <span class="n">itemgetter</span><span class="p">(</span><span class="s2">&quot;history&quot;</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="o">|</span> <span class="n">prompt</span>
    <span class="o">|</span> <span class="n">model</span>
<span class="p">)</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;hi, I&#39;m Bob&quot;</span><span class="p">}</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">response</span>

<span class="c1"># Save the conversation in memory</span>
<span class="n">memory</span><span class="o">.</span><span class="n">save_context</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="n">response</span><span class="o">.</span><span class="n">content</span><span class="p">})</span>

<span class="c1"># Load memory to see the conversation history</span>
<span class="n">memory</span><span class="o">.</span><span class="n">load_memory_variables</span><span class="p">({})</span>
</pre></div>
</div>
<p>이 예제에서 메모리는 대화 기록을 저장하고 검색하는 데 사용되어 챗봇이 컨텍스트를 유지하고 적절하게 응답할 수 있도록 합니다.</p>
</section>
<section id="runnables">
<h3>Runnables와 외부 도구 사용<a class="headerlink" href="#runnables" title="Link to this heading">#</a></h3>
<p>LCEL을 사용하면 외부 도구와 Runnables를 매끄럽게 통합할 수 있습니다. 다음은 DuckDuckGo 검색 도구를 사용한 예시입니다:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.chat_models</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="kn">from</span> <span class="nn">langchain.prompts</span> <span class="kn">import</span> <span class="n">ChatPromptTemplate</span>
<span class="kn">from</span> <span class="nn">langchain.schema.output_parser</span> <span class="kn">import</span> <span class="n">StrOutputParser</span>
<span class="kn">from</span> <span class="nn">langchain.tools</span> <span class="kn">import</span> <span class="n">DuckDuckGoSearchRun</span>

<span class="n">search</span> <span class="o">=</span> <span class="n">DuckDuckGoSearchRun</span><span class="p">()</span>

<span class="n">template</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;Turn the following user input into a search query for a search engine:</span>

<span class="si">{input}</span><span class="s2">&quot;&quot;&quot;</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="n">template</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">()</span>

<span class="n">chain</span> <span class="o">=</span> <span class="n">prompt</span> <span class="o">|</span> <span class="n">model</span> <span class="o">|</span> <span class="n">StrOutputParser</span><span class="p">()</span> <span class="o">|</span> <span class="n">search</span>

<span class="n">search_result</span> <span class="o">=</span> <span class="n">chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;I&#39;d like to figure out what games are tonight&quot;</span><span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="n">search_result</span><span class="p">)</span>
</pre></div>
</div>
<p>이 예제에서 LCEL은 DuckDuckGo 검색 도구를 체인에 통합하여 사용자 입력에서 검색 쿼리를 생성하고 검색 결과를 검색할 수 있습니다.</p>
<p>LCEL의 유연성으로 인해 다양한 외부 도구와 서비스를 언어 처리 파이프라인에 쉽게 통합할 수 있어 기능과 기능이 향상됩니다.</p>
</section>
<section id="id7">
<h3>LLM 애플리케이션에 중재 추가<a class="headerlink" href="#id7" title="Link to this heading">#</a></h3>
<p>LLM 애플리케이션이 콘텐츠 정책을 준수하고 중재 안전 장치를 포함하도록 하려면 체인에 중재 확인을 통합할 수 있습니다. LangChain을 사용하여 중재를 추가하는 방법은 다음과 같습니다:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.chains</span> <span class="kn">import</span> <span class="n">OpenAIModerationChain</span>
<span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">OpenAI</span>
<span class="kn">from</span> <span class="nn">langchain.prompts</span> <span class="kn">import</span> <span class="n">ChatPromptTemplate</span>

<span class="n">moderate</span> <span class="o">=</span> <span class="n">OpenAIModerationChain</span><span class="p">()</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">()</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_messages</span><span class="p">([(</span><span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;repeat after me: </span><span class="si">{input}</span><span class="s2">&quot;</span><span class="p">)])</span>

<span class="n">chain</span> <span class="o">=</span> <span class="n">prompt</span> <span class="o">|</span> <span class="n">model</span>

<span class="c1"># Original response without moderation</span>
<span class="n">response_without_moderation</span> <span class="o">=</span> <span class="n">chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;you are stupid&quot;</span><span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="n">response_without_moderation</span><span class="p">)</span>

<span class="n">moderated_chain</span> <span class="o">=</span> <span class="n">chain</span> <span class="o">|</span> <span class="n">moderate</span>

<span class="c1"># Response after moderation</span>
<span class="n">response_after_moderation</span> <span class="o">=</span> <span class="n">moderated_chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;you are stupid&quot;</span><span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="n">response_after_moderation</span><span class="p">)</span>
</pre></div>
</div>
<p>이 예제에서 <code class="docutils literal notranslate"><span class="pre">OpenAIModerationChain</span></code>은 LLM에 의해 생성된 응답에 중재를 추가하는 데 사용됩니다. 중재 체인은 OpenAI의 콘텐츠 정책을 위반하는 내용이 있는지 응답을 확인합니다. 위반이 발견되면 그에 따라 응답에 플래그를 지정합니다.</p>
</section>
<section id="id8">
<h3>의미론적 유사성에 의한 라우팅<a class="headerlink" href="#id8" title="Link to this heading">#</a></h3>
<p>LCEL을 사용하면 사용자 입력의 의미론적 유사성을 기반으로 사용자 지정 라우팅 논리를 구현할 수 있습니다. 다음은 사용자 입력을 기반으로 체인 논리를 동적으로 결정하는 방법의 예시입니다:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.chat_models</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="kn">from</span> <span class="nn">langchain.embeddings</span> <span class="kn">import</span> <span class="n">OpenAIEmbeddings</span>
<span class="kn">from</span> <span class="nn">langchain.prompts</span> <span class="kn">import</span> <span class="n">PromptTemplate</span>
<span class="kn">from</span> <span class="nn">langchain.schema.output_parser</span> <span class="kn">import</span> <span class="n">StrOutputParser</span>
<span class="kn">from</span> <span class="nn">langchain.schema.runnable</span> <span class="kn">import</span> <span class="n">RunnableLambda</span><span class="p">,</span> <span class="n">RunnablePassthrough</span>
<span class="kn">from</span> <span class="nn">langchain.utils.math</span> <span class="kn">import</span> <span class="n">cosine_similarity</span>

<span class="n">physics_template</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;You are a very smart physics professor. </span><span class="se">\</span>
<span class="s2">You are great at answering questions about physics in a concise and easy to understand manner. </span><span class="se">\</span>
<span class="s2">When you don&#39;t know the answer to a question you admit that you don&#39;t know.</span>

<span class="s2">Here is a question:</span>
<span class="si">{query}</span><span class="s2">&quot;&quot;&quot;</span>

<span class="n">math_template</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;You are a very good mathematician. You are great at answering math questions. </span><span class="se">\</span>
<span class="s2">You are so good because you are able to break down hard problems into their component parts, </span><span class="se">\</span>
<span class="s2">answer the component parts, and then put them together to answer the broader question.</span>

<span class="s2">Here is a question:</span>
<span class="si">{query}</span><span class="s2">&quot;&quot;&quot;</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">OpenAIEmbeddings</span><span class="p">()</span>
<span class="n">prompt_templates</span> <span class="o">=</span> <span class="p">[</span><span class="n">physics_template</span><span class="p">,</span> <span class="n">math_template</span><span class="p">]</span>
<span class="n">prompt_embeddings</span> <span class="o">=</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">embed_documents</span><span class="p">(</span><span class="n">prompt_templates</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">prompt_router</span><span class="p">(</span><span class="nb">input</span><span class="p">):</span>
    <span class="n">query_embedding</span> <span class="o">=</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">embed_query</span><span class="p">(</span><span class="nb">input</span><span class="p">[</span><span class="s2">&quot;query&quot;</span><span class="p">])</span>
    <span class="n">similarity</span> <span class="o">=</span> <span class="n">cosine_similarity</span><span class="p">([</span><span class="n">query_embedding</span><span class="p">],</span> <span class="n">prompt_embeddings</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">most_similar</span> <span class="o">=</span> <span class="n">prompt_templates</span><span class="p">[</span><span class="n">similarity</span><span class="o">.</span><span class="n">argmax</span><span class="p">()]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Using MATH&quot;</span> <span class="k">if</span> <span class="n">most_similar</span> <span class="o">==</span> <span class="n">math_template</span> <span class="k">else</span> <span class="s2">&quot;Using PHYSICS&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">PromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="n">most_similar</span><span class="p">)</span>

<span class="n">chain</span> <span class="o">=</span> <span class="p">(</span>
    <span class="p">{</span><span class="s2">&quot;query&quot;</span><span class="p">:</span> <span class="n">RunnablePassthrough</span><span class="p">()}</span>
    <span class="o">|</span> <span class="n">RunnableLambda</span><span class="p">(</span><span class="n">prompt_router</span><span class="p">)</span>
    <span class="o">|</span> <span class="n">ChatOpenAI</span><span class="p">()</span>
    <span class="o">|</span> <span class="n">StrOutputParser</span><span class="p">()</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;query&quot;</span><span class="p">:</span> <span class="s2">&quot;What&#39;s a black hole&quot;</span><span class="p">}))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;query&quot;</span><span class="p">:</span> <span class="s2">&quot;What&#39;s a path integral&quot;</span><span class="p">}))</span>
</pre></div>
</div>
<p>이 예제에서 <code class="docutils literal notranslate"><span class="pre">prompt_router</span></code> 함수는 사용자 입력과 물리학 및 수학 질문에 대한 미리 정의된 프롬프트 템플릿 사이의 코사인 유사성을 계산합니다. 유사성 점수에 따라 체인은 가장 관련성이 높은 프롬프트 템플릿을 동적으로 선택하여 챗봇이 사용자의 질문에 적절하게 응답하도록 합니다.</p>
</section>
<section id="id9">
<h3>에이전트 및 Runnables 사용<a class="headerlink" href="#id9" title="Link to this heading">#</a></h3>
<p>LangChain을 사용하면 Runnables, 프롬프트, 모델 및 도구를 결합하여 에이전트를 생성할 수 있습니다. 다음은 에이전트를 구축하고 사용하는 방법의 예시입니다:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.agents</span> <span class="kn">import</span> <span class="n">XMLAgent</span><span class="p">,</span> <span class="n">tool</span><span class="p">,</span> <span class="n">AgentExecutor</span>
<span class="kn">from</span> <span class="nn">langchain.chat_models</span> <span class="kn">import</span> <span class="n">ChatAnthropic</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">ChatAnthropic</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;claude-2&quot;</span><span class="p">)</span>

<span class="nd">@tool</span>
<span class="k">def</span> <span class="nf">search</span><span class="p">(</span><span class="n">query</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Search things about current events.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="s2">&quot;32 degrees&quot;</span>

<span class="n">tool_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">search</span><span class="p">]</span>

<span class="c1"># Get prompt to use</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="n">XMLAgent</span><span class="o">.</span><span class="n">get_default_prompt</span><span class="p">()</span>

<span class="c1"># Logic for going from intermediate steps to a string to pass into the model</span>
<span class="k">def</span> <span class="nf">convert_intermediate_steps</span><span class="p">(</span><span class="n">intermediate_steps</span><span class="p">):</span>
    <span class="n">log</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
    <span class="k">for</span> <span class="n">action</span><span class="p">,</span> <span class="n">observation</span> <span class="ow">in</span> <span class="n">intermediate_steps</span><span class="p">:</span>
        <span class="n">log</span> <span class="o">+=</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;&lt;tool&gt;</span><span class="si">{</span><span class="n">action</span><span class="o">.</span><span class="n">tool</span><span class="si">}</span><span class="s2">&lt;/tool&gt;&lt;tool_input&gt;</span><span class="si">{</span><span class="n">action</span><span class="o">.</span><span class="n">tool_input</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;&lt;/tool_input&gt;&lt;observation&gt;</span><span class="si">{</span><span class="n">observation</span><span class="si">}</span><span class="s2">&lt;/observation&gt;&quot;</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">log</span>

<span class="c1"># Logic for converting tools to a string to go in the prompt</span>
<span class="k">def</span> <span class="nf">convert_tools</span><span class="p">(</span><span class="n">tools</span><span class="p">):</span>
    <span class="k">return</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">tool</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">tool</span><span class="o">.</span><span class="n">description</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">tool</span> <span class="ow">in</span> <span class="n">tools</span><span class="p">])</span>

<span class="n">agent</span> <span class="o">=</span> <span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;question&quot;</span><span class="p">],</span>
        <span class="s2">&quot;intermediate_steps&quot;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">convert_intermediate_steps</span><span class="p">(</span>
            <span class="n">x</span><span class="p">[</span><span class="s2">&quot;intermediate_steps&quot;</span><span class="p">]</span>
        <span class="p">),</span>
    <span class="p">}</span>
    <span class="o">|</span> <span class="n">prompt</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">tools</span><span class="o">=</span><span class="n">convert_tools</span><span class="p">(</span><span class="n">tool_list</span><span class="p">))</span>
    <span class="o">|</span> <span class="n">model</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">stop</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;&lt;/tool_input&gt;&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;/final_answer&gt;&quot;</span><span class="p">])</span>
    <span class="o">|</span> <span class="n">XMLAgent</span><span class="o">.</span><span class="n">get_default_output_parser</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">agent_executor</span> <span class="o">=</span> <span class="n">AgentExecutor</span><span class="p">(</span><span class="n">agent</span><span class="o">=</span><span class="n">agent</span><span class="p">,</span> <span class="n">tools</span><span class="o">=</span><span class="n">tool_list</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">agent_executor</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;What&#39;s the weather in New York?&quot;</span><span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
<p>이 예제에서 모델, 도구, 프롬프트 및 중간 단계와 도구 변환을 위한 사용자 지정 논리를 결합하여 에이전트를 생성합니다. 그런 다음 에이전트를 실행하여 사용자의 쿼리에 대한 응답을 제공합니다.</p>
</section>
<section id="sql">
<h3>SQL 데이터베이스 쿼리<a class="headerlink" href="#sql" title="Link to this heading">#</a></h3>
<p>LangChain을 사용하여 SQL 데이터베이스를 쿼리하고 사용자 질문을 기반으로 SQL 쿼리를 생성할 수 있습니다. 다음은 그 예시입니다:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.prompts</span> <span class="kn">import</span> <span class="n">ChatPromptTemplate</span>

<span class="n">template</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;Based on the table schema below, write a SQL query that would answer the user&#39;s question:</span>
<span class="si">{schema}</span>

<span class="s2">Question: </span><span class="si">{question}</span>
<span class="s2">SQL Query:&quot;&quot;&quot;</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="n">template</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">langchain.utilities</span> <span class="kn">import</span> <span class="n">SQLDatabase</span>

<span class="c1"># Initialize the database (you&#39;ll need the Chinook sample DB for this example)</span>
<span class="n">db</span> <span class="o">=</span> <span class="n">SQLDatabase</span><span class="o">.</span><span class="n">from_uri</span><span class="p">(</span><span class="s2">&quot;sqlite:///./Chinook.db&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_schema</span><span class="p">(</span><span class="n">_</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">db</span><span class="o">.</span><span class="n">get_table_info</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">run_query</span><span class="p">(</span><span class="n">query</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">db</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">langchain.chat_models</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="kn">from</span> <span class="nn">langchain.schema.output_parser</span> <span class="kn">import</span> <span class="n">StrOutputParser</span>
<span class="kn">from</span> <span class="nn">langchain.schema.runnable</span> <span class="kn">import</span> <span class="n">RunnablePassthrough</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">()</span>

<span class="n">sql_response</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">RunnablePassthrough</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">schema</span><span class="o">=</span><span class="n">get_schema</span><span class="p">)</span>
    <span class="o">|</span> <span class="n">prompt</span>
    <span class="o">|</span> <span class="n">model</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">stop</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">SQLResult:&quot;</span><span class="p">])</span>
    <span class="o">|</span> <span class="n">StrOutputParser</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">sql_response</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;How many employees are there?&quot;</span><span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

<span class="n">template</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;Based on the table schema below, question, SQL query, and SQL response, write a natural language response:</span>
<span class="si">{schema}</span>

<span class="s2">Question: </span><span class="si">{question}</span>
<span class="s2">SQL Query: </span><span class="si">{query}</span>
<span class="s2">SQL Response: </span><span class="si">{response}</span><span class="s2">&quot;&quot;&quot;</span>
<span class="n">prompt_response</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="n">template</span><span class="p">)</span>

<span class="n">full_chain</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">RunnablePassthrough</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">query</span><span class="o">=</span><span class="n">sql_response</span><span class="p">)</span>
    <span class="o">|</span> <span class="n">RunnablePassthrough</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span>
        <span class="n">schema</span><span class="o">=</span><span class="n">get_schema</span><span class="p">,</span>
        <span class="n">response</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">db</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s2">&quot;query&quot;</span><span class="p">]),</span>
    <span class="p">)</span>
    <span class="o">|</span> <span class="n">prompt_response</span>
    <span class="o">|</span> <span class="n">model</span>
<span class="p">)</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">full_chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;How many employees are there?&quot;</span><span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</pre></div>
</div>
<p>이 예제에서 LangChain은 사용자 질문을 기반으로 SQL 쿼리를 생성하고 SQL 데이터베이스에서 응답을 검색하는 데 사용됩니다. 프롬프트와 응답은 데이터베이스와의 자연어 상호 작용을 제공하기 위해 포맷됩니다.</p>
<p>LangChain Expression Language(LCEL)은 복잡한 언어 처리 파이프라인을 구축하고 배포하는 데 필요한 유연성과 표현력을 제공합니다. 프롬프트, 언어 모델, 출력 파서를 결합하는 기본적인 것부터 검색 증강 생성, 대화형 검색, 메모리 사용, 분기 및 병합, Python 코드 생성, 에이전트 생성, SQL 데이터베이스 쿼리에 이르기까지 다양한 사용 사례와 시나리오를 다룹니다.</p>
<p>LCEL의 주요 이점 중 일부는 다음과 같습니다:</p>
<ol class="arabic simple">
<li><p>직관적인 구문: LCEL의 선언적 구문은 복잡한 파이프라인을 쉽게 표현할 수 있게 해줍니다.</p></li>
<li><p>모듈성: LCEL의 구성 요소 기반 아키텍처를 통해 개발자는 재사용 가능한 구성 요소를 만들고 다양한 사용 사례에 적용할 수 있습니다.</p></li>
<li><p>확장성: LCEL은 분산 환경에서 병렬 처리 및 스케일아웃을 지원하여 대규모 워크로드를 처리할 수 있습니다.</p></li>
<li><p>통합: LCEL은 외부 도구, 서비스 및 데이터 소스와의 원활한 통합을 가능하게 하여 언어 처리 파이프라인의 기능을 확장합니다.</p></li>
<li><p>관찰 가능성: LCEL의 포괄적인 추적 및 모니터링 기능을 통해 개발자는 복잡한 파이프라인의 동작을 이해하고 디버그할 수 있습니다.</p></li>
</ol>
<p>LCEL은 자연어 처리와 기계 학습의 빠르게 발전하는 분야에서 강력하고 유연한 도구입니다. 개발자가 정교한 언어 처리 애플리케이션을 빌드하고 배포할 수 있는 직관적이고 표현력 있는 방법을 제공함으로써 LCEL은 대화형 AI, 콘텐츠 생성, 의미 검색 등 다양한 사용 사례를 가능하게 합니다.</p>
<p>개발자는 LCEL을 사용하여 최첨단 언어 모델과 고급 검색 및 메모리 기술을 활용하는 강력한 언어 기반 애플리케이션을 만들 수 있습니다. 또한 LCEL의 모듈식 아키텍처와 확장 가능한 설계를 통해 개발자는 특정 사용 사례와 요구 사항에 맞게 파이프라인을 쉽게 사용자 정의하고 최적화할 수 있습니다.</p>
<p>LCEL의 통합 기능을 통해 개발자는 SQL 데이터베이스, 검색 엔진, 외부 API 등 다양한 데이터 소스와 서비스를 원활하게 통합할 수 있습니다. 이를 통해 언어 처리 파이프라인을 풍부한 데이터와 도메인 전문 지식으로 강화하여 더욱 정확하고 관련성 있는 결과를 얻을 수 있습니다.</p>
<p>종합적으로 LangChain Expression Language는 현대 언어 기반 애플리케이션을 구축하기 위한 강력하고 유연한 프레임워크를 제공합니다. 직관적인 구문, 모듈식 설계, 확장성을 갖춘 LCEL은 자연어 처리와 기계 학습 분야에서 개발자가 혁신적인 솔루션을 만드는 데 있어 귀중한 도구입니다.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "chu-aie/mlops-2024",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./week13"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="index.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Week 13</p>
      </div>
    </a>
    <a class="right-next"
       href="langchain-retrieval.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">LangChain 모듈 - 검색</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#llm">프롬프트 + LLM</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">프롬프트 + LLM + 출력 파서</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rag">RAG (검색 증강 생성)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">대화형 검색 체인</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">메모리 사용 및 소스 문서 반환</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">다중 체인</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">분기 및 병합</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lcel-python">LCEL을 사용하여 Python 코드 작성</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">체인에 메모리 추가</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#runnables">Runnables와 외부 도구 사용</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">LLM 애플리케이션에 중재 추가</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">의미론적 유사성에 의한 라우팅</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">에이전트 및 Runnables 사용</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sql">SQL 데이터베이스 쿼리</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By <a href='https://entelecheia.me/'>Young Joon Lee</a>
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <script
  data-embed-id="ed04ae65-928c-4ab5-912d-ce49f76450b7"
  data-base-api-url="https://chat.entelecheia.app/api/embed"
  data-brand-image-url="https://assets.entelecheia.ai/favicon.png"
  data-chat-icon="magic"
  data-sponsor-text="MLOps 2024"
  data-sponsor-link="https://chat.entelecheia.app/workspace/mlops2024"
  src="https://chat.entelecheia.app/embed/anythingllm-chat-widget.min.js">
</script>

</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>